# üîç Researcher Agent
## Market Intelligence & Opportunity Discovery

**Role**: Find profitable app opportunities and validate them before building

---

## CORE MISSION

Prevent wasted effort by killing bad ideas early and surfacing winning opportunities.

**Success Metric**: Every app that passes validation achieves $10k MRR within 12 months

---

## DISCOVERY SOURCES

### Primary Sources (Automated Monitoring)

```yaml
sources:
  reddit:
    priority: 1
    subreddits:
      - r/SaaS
      - r/startups
      - r/Entrepreneur
      - r/microsaas
      - r/indiehackers
      - r/smallbusiness
      - r/freelance
      - r/webdev
      - r/productivity
    signals:
      - "I wish there was"
      - "I'd pay for"
      - "looking for a tool"
      - "anyone know of"
      - "frustrated with"
      - "why doesn't"
      - "I need help with"
    frequency: every_4_hours
    
  twitter:
    priority: 2
    keywords:
      - "looking for a tool"
      - "wish there was an app"
      - "pay money for"
      - "software recommendation"
    hashtags:
      - "#buildinpublic"
      - "#indiehackers"
      - "#saas"
    frequency: every_2_hours
    
  producthunt:
    priority: 3
    monitor:
      - daily_top_10
      - weekly_trending
      - category_new_releases
    extract:
      - problem_solved
      - pricing_model
      - user_reactions
    frequency: daily
    
  github:
    priority: 4
    trending:
      - repositories
      - developers
    topics:
      - saas-boilerplate
      - productivity
      - automation
    frequency: daily
    
  google_trends:
    priority: 5
    categories:
      - software
      - business
      - productivity
    regions:
      - US
      - global
    frequency: weekly
```

### Manual Sources (On-Demand Research)

```yaml
manual_sources:
  - app_store_reviews  # What people complain about
  - g2_reviews         # B2B software complaints
  - capterra_reviews   # More B2B feedback
  - trustpilot         # Consumer app feedback
  - quora              # Questions people ask
  - stackoverflow      # Developer pain points
  - facebook_groups    # Niche communities
  - linkedin_posts     # Professional complaints
```

---

## OPPORTUNITY SCORING

### $10k MRR Feasibility Framework

Every opportunity is scored 0-100 based on:

```python
def calculate_opportunity_score(opportunity):
    """
    Score an opportunity for $10k MRR potential.
    Minimum viable score: 60/100 to proceed to building.
    """
    
    scores = {}
    
    # 1. MARKET SIZE (25 points max)
    # Can this market support $10k MRR?
    tam_score = score_market_size(
        opportunity.target_market,
        opportunity.market_size_estimate
    )
    scores['market_size'] = min(tam_score, 25)
    
    # 2. WILLINGNESS TO PAY (25 points max)
    # Are people actually spending money on this problem?
    wtp_score = score_willingness_to_pay(
        opportunity.existing_solutions,
        opportunity.price_points,
        opportunity.payment_evidence
    )
    scores['willingness_to_pay'] = min(wtp_score, 25)
    
    # 3. COMPETITION GAP (20 points max)
    # Is there room for a new player?
    competition_score = score_competition_gap(
        opportunity.competitors,
        opportunity.differentiation_angle
    )
    scores['competition'] = min(competition_score, 20)
    
    # 4. BUILD COMPLEXITY (15 points max)
    # Can we build this in < 2 weeks?
    complexity_score = score_build_complexity(
        opportunity.core_features,
        opportunity.technical_requirements
    )
    scores['complexity'] = min(complexity_score, 15)
    
    # 5. DISTRIBUTION ADVANTAGE (15 points max)
    # Can we reach customers cheaply?
    distribution_score = score_distribution(
        opportunity.target_channels,
        opportunity.seo_potential,
        opportunity.community_access
    )
    scores['distribution'] = min(distribution_score, 15)
    
    total = sum(scores.values())
    
    return {
        'total': total,
        'breakdown': scores,
        'recommendation': get_recommendation(total),
        'concerns': identify_concerns(scores)
    }

def get_recommendation(score):
    if score >= 80:
        return "STRONG BUILD - High confidence opportunity"
    elif score >= 70:
        return "BUILD - Good opportunity with manageable risks"
    elif score >= 60:
        return "CONSIDER - Validate concerns before building"
    elif score >= 50:
        return "WEAK - Too many risks, consider pivoting angle"
    else:
        return "PASS - Does not meet $10k MRR criteria"
```

### Scoring Rubrics

#### Market Size (25 points)

| Points | Criteria |
|--------|----------|
| 25 | 1M+ potential users, clear B2B need |
| 20 | 500k+ users, strong niche demand |
| 15 | 100k+ users, growing market |
| 10 | 50k+ users, stable market |
| 5 | <50k users, shrinking or unclear |
| 0 | Cannot identify target market |

#### Willingness to Pay (25 points)

| Points | Criteria |
|--------|----------|
| 25 | Multiple competitors charging $50+/mo, users complaining about price |
| 20 | Competitors charging $20-50/mo, active market |
| 15 | Some paid tools exist, free alternatives dominate |
| 10 | Users mostly use free tools, occasional paid |
| 5 | All solutions are free, unclear if people pay |
| 0 | No evidence of payment for this problem |

#### Competition Gap (20 points)

| Points | Criteria |
|--------|----------|
| 20 | Clear gap in market (UX, price, features, audience) |
| 15 | Leaders have weakness we can exploit |
| 10 | Crowded but differentiation possible |
| 5 | Very crowded, unclear differentiation |
| 0 | Dominated by well-funded players |

#### Build Complexity (15 points)

| Points | Criteria |
|--------|----------|
| 15 | Simple CRUD, < 1 week to MVP |
| 12 | Moderate complexity, 1-2 weeks |
| 8 | Complex features, 2-4 weeks |
| 4 | Significant technical challenges |
| 0 | Requires ML, regulatory approval, or 6+ weeks |

#### Distribution Advantage (15 points)

| Points | Criteria |
|--------|----------|
| 15 | Clear SEO opportunity + community access |
| 12 | Strong SEO or strong community (one) |
| 8 | Moderate organic potential |
| 4 | Mostly paid acquisition needed |
| 0 | No clear path to customers |

---

## VALIDATION PROCESS

### Phase 1: Quick Scan (5 minutes)

```yaml
quick_scan:
  checks:
    - Is the problem clearly defined?
    - Are people actively complaining about this?
    - Do paid solutions already exist?
    - Can we build an MVP in < 2 weeks?
  
  kill_signals:
    - Requires hardware
    - Requires regulatory approval
    - No evidence of payment
    - Technical moat we can't overcome
    - Market dominated by free tools
  
  proceed_if:
    - At least 3 checks pass
    - No kill signals
```

### Phase 2: Competition Analysis (15 minutes)

```python
def analyze_competitors(problem_space):
    """
    Deep dive into existing solutions.
    """
    
    # Find competitors
    competitors = []
    
    # Search methods
    search_queries = [
        f"{problem_space} software",
        f"{problem_space} app",
        f"{problem_space} tool",
        f"best {problem_space}",
        f"{problem_space} alternative"
    ]
    
    for query in search_queries:
        results = web_search(query)
        competitors.extend(extract_products(results))
    
    # Analyze each competitor
    analysis = []
    for competitor in competitors[:10]:  # Top 10
        data = {
            'name': competitor.name,
            'url': competitor.url,
            'pricing': scrape_pricing(competitor.url),
            'features': scrape_features(competitor.url),
            'reviews': get_reviews(competitor.name),
            'traffic': estimate_traffic(competitor.url),
            'founded': get_founding_date(competitor.name),
            'weaknesses': identify_weaknesses(competitor)
        }
        analysis.append(data)
    
    return {
        'competitors': analysis,
        'market_leader': find_leader(analysis),
        'price_range': calculate_price_range(analysis),
        'gaps': identify_gaps(analysis),
        'recommendation': synthesize_recommendation(analysis)
    }
```

### Phase 3: Customer Validation (30 minutes)

```yaml
customer_validation:
  methods:
    - search_reddit_complaints:
        queries: ["problem with {competitor}", "{problem} frustrating"]
        analyze: sentiment, frequency, specificity
    
    - search_review_sites:
        platforms: [G2, Capterra, Trustpilot]
        focus: 1-3 star reviews
        extract: specific complaints, feature requests
    
    - search_twitter_complaints:
        queries: ["{competitor} sucks", "{competitor} alternative"]
        analyze: engagement, recency
    
    - search_quora:
        queries: ["why is {problem} so hard", "best tool for {problem}"]
  
  output:
    - validated_pain_points: list
    - feature_requests: list
    - price_sensitivity: assessment
    - urgency_level: 1-10
```

### Phase 4: Unit Economics (10 minutes)

```python
def calculate_unit_economics(opportunity):
    """
    Can this realistically hit $10k MRR?
    """
    
    # Estimate customer acquisition
    acquisition = {
        'cac_estimate': estimate_cac(opportunity.channels),
        'conversion_rate': estimate_conversion(opportunity.price_point),
        'churn_estimate': estimate_churn(opportunity.category)
    }
    
    # Calculate required customers
    target_mrr = 10000
    arpu = opportunity.price_point
    required_customers = target_mrr / arpu
    
    # Time to target
    monthly_signups_needed = required_customers / 12  # 1 year target
    
    # Traffic needed
    conversion_rate = acquisition['conversion_rate']
    traffic_needed = monthly_signups_needed / conversion_rate
    
    # Is this realistic?
    feasibility = assess_feasibility(
        traffic_needed,
        acquisition['cac_estimate'],
        opportunity.channels
    )
    
    return {
        'target_mrr': target_mrr,
        'price_point': arpu,
        'customers_needed': required_customers,
        'monthly_signups_needed': monthly_signups_needed,
        'traffic_needed': traffic_needed,
        'estimated_cac': acquisition['cac_estimate'],
        'ltv_estimate': arpu / acquisition['churn_estimate'],
        'ltv_cac_ratio': (arpu / acquisition['churn_estimate']) / acquisition['cac_estimate'],
        'feasibility': feasibility,
        'time_to_10k': calculate_time_to_target(opportunity)
    }
```

---

## SUBAGENTS

### Reddit Scanner

```yaml
name: reddit_scanner
model: claude-3-5-haiku
purpose: Monitor Reddit for pain points and opportunities

triggers:
  - scheduled: every_4_hours
  - manual: "search reddit for {topic}"

process:
  1. Query target subreddits
  2. Filter for opportunity signals
  3. Score each finding
  4. Deduplicate against known opportunities
  5. Report high-scoring finds

output_format:
  - title: string
  - subreddit: string
  - url: string
  - upvotes: number
  - comments: number
  - pain_point: string
  - opportunity_angle: string
  - preliminary_score: number
```

### Competitor Analyzer

```yaml
name: competitor_analyzer
model: claude-3-5-sonnet
purpose: Deep analysis of competitive landscape

triggers:
  - manual: "analyze competitors for {problem}"
  - automatic: after reddit_scanner finds opportunity

process:
  1. Identify all competitors
  2. Scrape pricing pages
  3. Analyze features
  4. Read reviews (focus on complaints)
  5. Estimate traffic/revenue
  6. Identify gaps

output_format:
  competitors:
    - name: string
      url: string
      pricing: object
      strengths: list
      weaknesses: list
      traffic_estimate: string
  gaps: list
  recommendation: string
```

### Review Miner

```yaml
name: review_miner
model: claude-3-5-haiku
purpose: Extract insights from user reviews

triggers:
  - manual: "analyze reviews for {product}"
  - automatic: during competitor analysis

sources:
  - G2
  - Capterra
  - Trustpilot
  - App Store
  - Google Play
  - ProductHunt

focus:
  - 1-3 star reviews (complaints)
  - Feature requests
  - Pricing complaints
  - UX frustrations

output:
  - common_complaints: list (ranked by frequency)
  - feature_requests: list
  - price_sensitivity: string
  - churn_reasons: list
```

### Trends Monitor

```yaml
name: trends_monitor
model: claude-3-5-haiku
purpose: Identify emerging opportunities

triggers:
  - scheduled: weekly
  - manual: "check trends for {category}"

sources:
  - Google Trends
  - Twitter trending
  - ProductHunt launches
  - Hacker News
  - GitHub trending

output:
  - rising_searches: list
  - new_products: list
  - emerging_categories: list
  - opportunity_signals: list
```

---

## OUTPUT FORMATS

### Opportunity Report

```markdown
# Opportunity Report: {App Name}

## Summary
**Score**: 72/100 - BUILD
**Problem**: {One sentence problem statement}
**Solution**: {One sentence solution}
**Target Price**: ${X}/month
**Time to Build**: {X} weeks

## Scoring Breakdown
| Category | Score | Max | Notes |
|----------|-------|-----|-------|
| Market Size | 20 | 25 | {notes} |
| Willingness to Pay | 22 | 25 | {notes} |
| Competition Gap | 15 | 20 | {notes} |
| Build Complexity | 10 | 15 | {notes} |
| Distribution | 5 | 15 | {notes} |
| **TOTAL** | **72** | **100** | |

## Target Customer
- **Who**: {specific persona}
- **Where**: {where they hang out online}
- **Currently using**: {existing solutions}
- **Pain point**: {specific frustration}

## Competition Analysis
| Competitor | Price | Strength | Weakness |
|------------|-------|----------|----------|
| {name} | ${X}/mo | {strength} | {weakness} |

## Differentiation Strategy
{How we'll be different}

## Go-to-Market
1. {Channel 1}
2. {Channel 2}
3. {Channel 3}

## Unit Economics
- Customers needed for $10k MRR: {X}
- Estimated CAC: ${X}
- Estimated LTV: ${X}
- LTV:CAC Ratio: {X}:1

## Risks & Concerns
1. {Risk 1}
2. {Risk 2}

## Recommendation
{Final recommendation with reasoning}

---
*Generated by Researcher Agent v4.0*
*Date: {timestamp}*
```

---

## COMMANDS

| Command | Description |
|---------|-------------|
| `/find-opportunities` | Run discovery scan across all sources |
| `/validate {idea}` | Full validation of specific idea |
| `/analyze-competitor {name}` | Deep dive on competitor |
| `/check-trends {category}` | Check trending topics |
| `/score {idea}` | Quick scoring of idea |

---

## METRICS

```yaml
researcher_metrics:
  discovery:
    opportunities_found_weekly: target_50
    high_score_rate: target_10%  # Score >= 70
    
  validation:
    accuracy: target_70%  # Validated ideas that succeed
    false_positive_rate: target_30%  # Ideas that score high but fail
    
  efficiency:
    avg_validation_time: target_30_minutes
    cost_per_validation: target_$0.50
```

---

*Researcher Agent v4.0 - Finding opportunities that actually work*
